{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecasting of daily River Discharge (RD) based on temperature and previous precipitation levels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import of libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import matplotlib.dates as mdates\n",
    "from sklearn import linear_model,preprocessing\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "from scipy.stats import boxcox\n",
    "from scipy.special import inv_boxcox\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LoadingData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(river,daysBefore,daysBefore2):\n",
    "    data=pd.read_csv(river).values\n",
    "    Xbefore = data[:,[0,2,3]]\n",
    "    second_colum = Xbefore[:,2]\n",
    "    second_colum2 = Xbefore[:,2]\n",
    "    second_colum = np.roll(second_colum,daysBefore)\n",
    "    second_colum2 = np.roll(second_colum2,daysBefore2)\n",
    "\n",
    "    new_column = np.expand_dims(second_colum, axis=1)\n",
    "    Xbefore = np.hstack((Xbefore, new_column))\n",
    "    new_column = np.expand_dims(second_colum2, axis=1)\n",
    "    Xbefore = np.hstack((Xbefore, new_column))\n",
    "    split = daysBefore if daysBefore > daysBefore2 else daysBefore2\n",
    "    \n",
    "    X = Xbefore[split:,:]\n",
    "    y = data[split:,1]\n",
    "    \n",
    "\n",
    "    return X,y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" X, y = loadData('RD_data/RD_VougaR_pg.csv',2,5)\\nX_78 = [day for day in X[:,0] if '1980' in day]\\nprint(len(X_78)) \""
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" X, y = loadData('RD_data/RD_VougaR_pg.csv',2,5)\n",
    "X_78 = [day for day in X[:,0] if '1980' in day]\n",
    "print(len(X_78)) \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prep of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_boxcox(y, lambda_val=0):\n",
    "    y_float64 = np.array(y, dtype=np.float64)\n",
    "    if lambda_val == 0:\n",
    "        res = boxcox(y_float64)\n",
    "    else:\n",
    "        res = boxcox(y_float64, lambda_val)\n",
    "    y = res[0]\n",
    "    lambda_val = res[1]\n",
    "    return y, lambda_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(X_trainN,y_train):\n",
    "\n",
    "    # Define a range of alpha values to test\n",
    "    alphas = [0.01,0.1,1,2,3,4,5,6,7,8,9,10,20,30,40,50,60,70,80,90,100]\n",
    "    ridge_cv = linear_model.RidgeCV(alphas=alphas, scoring=None)\n",
    "\n",
    "    # Create learning curve\n",
    "    train_sizes, train_errors, valid_errors = learning_curve(\n",
    "        ridge_cv, X_trainN, y_train, train_sizes=np.linspace(0.1, 1.0, 10),scoring=lambda estimator, X, y: mean_squared_error(y, estimator.predict(X)))\n",
    "\n",
    "    # Calculate mean and standard deviation of training and validation errors\n",
    "    train_errors_mean = np.mean(train_errors, axis=1)\n",
    "    train_errors_std = np.std(train_errors, axis=1)\n",
    "    valid_errors_mean = np.mean(valid_errors, axis=1)\n",
    "    valid_errors_std = np.std(valid_errors, axis=1)\n",
    "\n",
    "    # Plot learning curve\n",
    "    plt.figure()\n",
    "    plt.title(\"Learning Curve for RidgeCV\")\n",
    "    plt.xlabel(\"Training Examples\")\n",
    "    plt.ylabel(\"Error\")\n",
    "\n",
    "    plt.grid()\n",
    "\n",
    "    plt.plot(train_sizes, train_errors_mean, '-', color=\"r\",\n",
    "            label=\"Training score\")\n",
    "    plt.plot(train_sizes, valid_errors_mean, '-', color=\"g\",\n",
    "            label=\"Cross-validation score\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(X, y, years):\n",
    "    scaler = preprocessing.StandardScaler()\n",
    "    \n",
    "    yearsTraining= math.ceil((len(years)+1)/2) \n",
    "    X_trainN = []\n",
    "    for i in range(0,yearsTraining):\n",
    "        X_trainN += [row for row in X if years[i] in row[0]] \n",
    "    X_trainN = np.array(X_trainN)\n",
    "    X_trainN = X_trainN[:,1:]\n",
    "    y_train = y[:len(X_trainN)]\n",
    "    X_testN = X[len(X_trainN):,1:]\n",
    "    y_test = y[len(X_trainN):]\n",
    "\n",
    "    #plot_learning_curve(X_trainN, y_train)\n",
    "\n",
    "    X_train_scaled = scaler.fit_transform(X_trainN)\n",
    "    y_train_boxcox, lambda_val = apply_boxcox(y_train)\n",
    "    \n",
    "    X_test_scaled = scaler.transform(X_testN)\n",
    "    \n",
    "    return X_train_scaled, y_train_boxcox, X_test_scaled, y_test, lambda_val\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(X_train_scaled, y_train_boxcox, X_test_scaled, y_test, lambda_val):\n",
    "    \n",
    "    alphas = [0.01,0.1,1,2,3,4,5,6,7,8,9,10,100,1000]\n",
    "    ridge_cv = linear_model.RidgeCV(alphas=alphas)\n",
    "\n",
    "    ridge_cv.fit(X_train_scaled,y_train_boxcox)\n",
    "    best_alpha = ridge_cv.alpha_\n",
    "    y_predict = inv_boxcox(ridge_cv.predict(X_test_scaled), lambda_val)\n",
    "\n",
    "    r2_training = ridge_cv.score(X_train_scaled, y_train_boxcox)\n",
    "    rmse_training = np.sqrt(-1*ridge_cv.best_score_)\n",
    "\n",
    "    r2 = r2_score(y_test, y_predict)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_predict))\n",
    "\n",
    "    \"\"\" plt.plot(y_test, 'r', label='Original')\n",
    "    plt.plot(y_predict, 'b', label='Predicted')\n",
    "    ax = plt.gca()\n",
    "    ax.set_ylim([0, ax.get_ylim()[1]*1.1])\n",
    "    plt.legend()\n",
    "    plt.show() \"\"\"\n",
    "\n",
    "    return r2, rmse, r2_training, rmse_training, best_alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test different memories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_for_river(river, years):\n",
    "\n",
    "    best_r2 = (-np.inf,0,0)\n",
    "    best_rmse = (np.inf,0,0)\n",
    "\n",
    "    memory = [x for x in range(0,11)] + [x for x in range(30,360,30)]\n",
    "\n",
    "    for i in memory:\n",
    "        for j in memory:\n",
    "            X, y = loadData(river, i, j)\n",
    "            X_train_scaled, y_train_boxcox, X_test_scaled, y_test, lambda_val = preprocess_data(X, y, years)\n",
    "            r2, rmse, _, _, _ = fit(X_train_scaled, y_train_boxcox, X_test_scaled, y_test, lambda_val)\n",
    "            if r2 > best_r2[0]:\n",
    "                best_r2 = (r2, i, j)\n",
    "            if rmse < best_rmse[0]:\n",
    "                best_rmse = (rmse, i, j)\n",
    "            \n",
    "    print(\"\\n\\n ----- TESTING FOR RIVER:\", river + \" ------ \\n\\n\")\n",
    "    print(\"Best i and j for best R2:\", best_r2[1:])\n",
    "    print(\"Best i and j for best RMSE:\", best_rmse[1:])\n",
    "    X, y = loadData(river, best_r2[1], best_r2[2])\n",
    "    X_train_scaled, y_train_boxcox, X_test_scaled, y_test, lambda_val = preprocess_data(X, y, years)\n",
    "    r2, rmse, r2_train, rmse_train, best_alpha = fit(X_train_scaled, y_train_boxcox, X_test_scaled, y_test, lambda_val)\n",
    "    print(\"RMSE training:\", rmse_train)\n",
    "    print(\"R2 training:\", r2_train)\n",
    "    print(\"RMSE test:\", rmse)\n",
    "    print(\"R2 test:\", r2)\n",
    "    print(\"Best alpha:\", best_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " ----- TESTING FOR RIVER: RD_data/RD_VougaR_pg.csv ------ \n",
      "\n",
      "\n",
      "Best i and j for best R2: (270, 4)\n",
      "Best i and j for best RMSE: (330, 4)\n",
      "RMSE training: 1.434446619456292\n",
      "R2 training: 0.7267815790011438\n",
      "RMSE test: 4.011815970372256\n",
      "R2 test: 0.7984799860269483\n",
      "Best alpha: 6.0\n"
     ]
    }
   ],
   "source": [
    "test_for_river(\"RD_data/RD_AntuaR_pg.csv\", [\"1985\",\"1986\",\"1987\",\"1988\",\"1989\"])\n",
    "test_for_river(\"RD_data/RD_MondegoR_pg.csv\", [\"1972\",\"1973\",\"1974\",\"1975\",\"1976\"])\n",
    "test_for_river(\"RD_data/RD_NeivaR_pg.csv\", [\"1984\",\"1985\",\"1986\",\"1987\",\"1988\",\"1989\"])\n",
    "test_for_river(\"RD_data/RD_VougaR_pg.csv\", [\"1978\", \"1979\", \"1980\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
