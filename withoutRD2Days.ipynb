{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecasting of daily River Discharge (RD) based on temperature and previous precipitation levels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import of libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import matplotlib.dates as mdates\n",
    "from sklearn import linear_model,preprocessing\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "from scipy.stats import boxcox\n",
    "from scipy.special import inv_boxcox\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LoadingData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(river,daysBefore,daysBefore2):\n",
    "    data=pd.read_csv(river).values\n",
    "    Xbefore = data[:,2:4]\n",
    "    second_colum = Xbefore[:,1]\n",
    "    second_colum2 = Xbefore[:,1]\n",
    "    \n",
    "    second_colum = np.roll(second_colum,daysBefore)\n",
    "    second_colum2 = np.roll(second_colum,daysBefore2)\n",
    "    new_column = np.expand_dims(second_colum, axis=1)\n",
    "    Xbefore = np.hstack((Xbefore, new_column))\n",
    "    new_column = np.expand_dims(second_colum2, axis=1)\n",
    "    Xbefore = np.hstack((Xbefore, new_column))\n",
    "    split = daysBefore if daysBefore > daysBefore2 else daysBefore2\n",
    "\n",
    "    X = Xbefore[split:,:]\n",
    "    y = data[split:,1]\n",
    "\n",
    "    return X,y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prep of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_boxcox(y, lambda_val=0):\n",
    "    y_float64 = np.array(y, dtype=np.float64)\n",
    "    if lambda_val == 0:\n",
    "        res = boxcox(y_float64)\n",
    "    else:\n",
    "        res = boxcox(y_float64, lambda_val)\n",
    "    y = res[0]\n",
    "    lambda_val = res[1]\n",
    "    return y, lambda_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(X_trainN,y_train):\n",
    "\n",
    "    # Define a range of alpha values to test\n",
    "    alphas = [0.01,0.1,1,2,3,4,5,6,7,8,9,10,20,30,40,50,60,70,80,90,100]\n",
    "    ridge_cv = linear_model.RidgeCV(alphas=alphas, scoring=None)\n",
    "\n",
    "    # Create learning curve\n",
    "    train_sizes, train_errors, valid_errors = learning_curve(\n",
    "        ridge_cv, X_trainN, y_train, train_sizes=np.linspace(0.1, 1.0, 10),scoring=lambda estimator, X, y: mean_squared_error(y, estimator.predict(X)))\n",
    "\n",
    "    # Calculate mean and standard deviation of training and validation errors\n",
    "    train_errors_mean = np.mean(train_errors, axis=1)\n",
    "    train_errors_std = np.std(train_errors, axis=1)\n",
    "    valid_errors_mean = np.mean(valid_errors, axis=1)\n",
    "    valid_errors_std = np.std(valid_errors, axis=1)\n",
    "\n",
    "    # Plot learning curve\n",
    "    plt.figure()\n",
    "    plt.title(\"Learning Curve for RidgeCV\")\n",
    "    plt.xlabel(\"Training Examples\")\n",
    "    plt.ylabel(\"Error\")\n",
    "\n",
    "    plt.grid()\n",
    "\n",
    "    plt.plot(train_sizes, train_errors_mean, '-', color=\"r\",\n",
    "            label=\"Training score\")\n",
    "    plt.plot(train_sizes, valid_errors_mean, '-', color=\"g\",\n",
    "            label=\"Cross-validation score\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(X, y):\n",
    "    scaler = preprocessing.StandardScaler()\n",
    "\n",
    "    X_trainN, X_testN, y_train, y_test = train_test_split(X, y, train_size=0.8, shuffle=False)\n",
    "\n",
    "    #plot_learning_curve(X_trainN, y_train)\n",
    "\n",
    "    X_train_scaled = scaler.fit_transform(X_trainN)\n",
    "    y_train_boxcox, lambda_val = apply_boxcox(y_train)\n",
    "    \n",
    "    X_test_scaled = scaler.transform(X_testN)\n",
    "    y_test_boxcox, _ = apply_boxcox(y_test, lambda_val)\n",
    "    \n",
    "    return X_train_scaled, y_train_boxcox, X_test_scaled, y_test, lambda_val\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(X_train_scaled, y_train_boxcox, X_test_scaled, y_test, lambda_val):\n",
    "    \n",
    "    alphas = [0.01,0.1,1,2,3,4,5,6,7,8,9,10,100,1000]\n",
    "    ridge_cv = linear_model.RidgeCV(alphas=alphas)\n",
    "\n",
    "    ridge_cv.fit(X_train_scaled,y_train_boxcox)\n",
    "    best_alpha = ridge_cv.alpha_\n",
    "    y_predict = inv_boxcox(ridge_cv.predict(X_test_scaled), lambda_val)\n",
    "\n",
    "    r2_training = ridge_cv.score(X_train_scaled, y_train_boxcox)\n",
    "    rmse_training = np.sqrt(-1*ridge_cv.best_score_)\n",
    "\n",
    "    r2 = r2_score(y_test, y_predict)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_predict))\n",
    "\n",
    "    \"\"\" plt.plot(y_test, 'r', label='Original')\n",
    "    plt.plot(y_predict, 'b', label='Predicted')\n",
    "    ax = plt.gca()\n",
    "    ax.set_ylim([0, ax.get_ylim()[1]*1.1])\n",
    "    plt.legend()\n",
    "    plt.show() \"\"\"\n",
    "\n",
    "    return r2, rmse, r2_training, rmse_training, best_alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test different memories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_for_river(river):\n",
    "\n",
    "    best_r2 = (-np.inf,0,0)\n",
    "    best_rmse = (np.inf,0,0)\n",
    "\n",
    "    for i in range(0,11):\n",
    "        for j in range(0,11):\n",
    "            X, y = loadData(river, i, j)\n",
    "            X_train_scaled, y_train_boxcox, X_test_scaled, y_test, lambda_val = preprocess_data(X, y)\n",
    "            r2, rmse, _, _, _ = fit(X_train_scaled, y_train_boxcox, X_test_scaled, y_test, lambda_val)\n",
    "            if r2 > best_r2[0]:\n",
    "                best_r2 = (r2, i, j)\n",
    "            if rmse < best_rmse[0]:\n",
    "                best_rmse = (rmse, i, j)\n",
    "            \n",
    "    print(\"\\n\\n ----- TESTING FOR RIVER:\", river + \" ------ \\n\\n\")\n",
    "    print(\"Best i and j for best R2:\", best_r2[1:])\n",
    "    print(\"Best i and j for best RMSE:\", best_rmse[1:])\n",
    "    X, y = loadData(river, best_r2[1], best_r2[2])\n",
    "    X_train_scaled, y_train_boxcox, X_test_scaled, y_test, lambda_val = preprocess_data(X, y)\n",
    "    r2, rmse, r2_train, rmse_train, best_alpha = fit(X_train_scaled, y_train_boxcox, X_test_scaled, y_test, lambda_val)\n",
    "    print(\"RMSE training:\", rmse_train)\n",
    "    print(\"R2 training:\", r2_train)\n",
    "    print(\"RMSE test:\", rmse)\n",
    "    print(\"R2 test:\", r2)\n",
    "    print(\"Best alpha:\", best_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " ----- TESTING FOR RIVER: RD_data/RD_AntuaR_pg.csv ------ \n",
      "\n",
      "\n",
      "Best i and j for best R2: (2, 6)\n",
      "Best i and j for best RMSE: (2, 6)\n",
      "RMSE training: 0.7397902509665072\n",
      "R2 training: 0.6589631179006177\n",
      "RMSE test: 2.0167090161015704\n",
      "R2 test: -0.3416062941809679\n",
      "Best alpha: 7.0\n",
      "\n",
      "\n",
      " ----- TESTING FOR RIVER: RD_data/RD_MondegoR_pg.csv ------ \n",
      "\n",
      "\n",
      "Best i and j for best R2: (7, 7)\n",
      "Best i and j for best RMSE: (7, 7)\n",
      "RMSE training: 1.2297896286401186\n",
      "R2 training: 0.5954359471134865\n",
      "RMSE test: 28.847990667256813\n",
      "R2 test: -5.456159761461806\n",
      "Best alpha: 10.0\n",
      "\n",
      "\n",
      " ----- TESTING FOR RIVER: RD_data/RD_NeivaR_pg.csv ------ \n",
      "\n",
      "\n",
      "Best i and j for best R2: (5, 5)\n",
      "Best i and j for best RMSE: (5, 5)\n",
      "RMSE training: 0.6274772790677154\n",
      "R2 training: 0.6651424970428215\n",
      "RMSE test: 1.2836456362934148\n",
      "R2 test: -0.714287715970523\n",
      "Best alpha: 8.0\n",
      "\n",
      "\n",
      " ----- TESTING FOR RIVER: RD_data/RD_VougaR_pg.csv ------ \n",
      "\n",
      "\n",
      "Best i and j for best R2: (4, 4)\n",
      "Best i and j for best RMSE: (4, 4)\n",
      "RMSE training: 1.1132379766542724\n",
      "R2 training: 0.7567542405774451\n",
      "RMSE test: 15.314224461384097\n",
      "R2 test: 0.7222200074883158\n",
      "Best alpha: 4.0\n"
     ]
    }
   ],
   "source": [
    "test_for_river(\"RD_data/RD_AntuaR_pg.csv\")\n",
    "test_for_river(\"RD_data/RD_MondegoR_pg.csv\")\n",
    "test_for_river(\"RD_data/RD_NeivaR_pg.csv\")\n",
    "test_for_river(\"RD_data/RD_VougaR_pg.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
